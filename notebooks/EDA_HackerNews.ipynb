{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "0cfe8e8e",
      "metadata": {},
      "source": [
        "# Hacker News Upvote Prediction: Exploratory Data Analysis (EDA)\n",
        "\n",
        "Welcome to the EDA phase of the Hacker News Upvote Prediction project! This notebook shows how to:\n",
        "\n",
        "1. Connect to the database and extract a 100k-row sample of posts\n",
        "2. Inspect and visualize the data for outliers, distributions, and basic relationships\n",
        "3. Prompt deeper investigation by posing guiding questions\n",
        "\n",
        "We'll use **matplotlib** for plots, **pandas** for data manipulation, and **sqlalchemy** (or `psycopg2`) for database connections.\n",
        "\n",
        "> **Tip**: If you have a local file or already-downloaded data, you can skip the database connection and simply load the data directly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cbea306d",
      "metadata": {
        "collapsed": false
      },
      "outputs": [],
      "source": [
        "# -- Install any missing libraries (run in separate terminal or comment out as needed)\n",
        "# !pip install pandas sqlalchemy psycopg2 matplotlib\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sqlalchemy import create_engine\n",
        "\n",
        "# If you want inline plots in Jupyter, uncomment:\n",
        "%matplotlib inline\n",
        "\n",
        "print('Libraries imported successfully!')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3a05b53f",
      "metadata": {},
      "source": [
        "## 1. Database Connection & Data Extraction\n",
        "Here, we connect to the Postgres database and sample about 100,000 rows.\n",
        "\n",
        "### Strategic Questions\n",
        "- **How** did you decide on 100k? Could you choose more or fewer rows?\n",
        "- **Do you need** to randomize the selection for representativeness?\n",
        "- **Is the `title` column** ever missing (NULL)? Should you filter on that?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bde36ead",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example connection string. Replace with your actual credentials:\n",
        "USERNAME = 'YOUR_USERNAME'\n",
        "PASSWORD = 'YOUR_PASSWORD'\n",
        "HOST     = 'YOUR_HOST'\n",
        "PORT     = 'YOUR_PORT'  # e.g. 5432\n",
        "DBNAME   = 'YOUR_DBNAME'\n",
        "\n",
        "connection_string = f\"postgresql://{USERNAME}:{PASSWORD}@{HOST}:{PORT}/{DBNAME}\"\n",
        "engine = create_engine(connection_string)\n",
        "\n",
        "# Adjust schema/table names to match your environment\n",
        "QUERY = '''\n",
        "SELECT *\n",
        "FROM \"hacker_news\".\"items\"\n",
        "WHERE title IS NOT NULL\n",
        "ORDER BY random()\n",
        "LIMIT 100000;\n",
        "'''\n",
        "\n",
        "df = pd.read_sql(QUERY, engine)\n",
        "print(f\"DataFrame shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e7f0ca72",
      "metadata": {},
      "source": [
        "## 2. Basic Data Inspection\n",
        "Get a feel for what columns are available, data types, and missing values.\n",
        "\n",
        "### Strategic Questions\n",
        "- **Which columns** do you expect to be most predictive of upvotes?\n",
        "- **Which columns** might need cleaning (e.g., domain, author)?\n",
        "- **Are there any** columns that are entirely null or rarely populated?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8521015",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Info and summary stats\n",
        "df.info()\n",
        "df.describe(include=\"all\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8071bdf1",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Check for nulls or missing data\n",
        "missing_counts = df.isnull().sum()\n",
        "print(\"Missing values in each column:\\n\", missing_counts)\n",
        "\n",
        "# If you have time columns, convert them if needed:\n",
        "# e.g., if 'time' is a UNIX timestamp, do:\n",
        "# df['time'] = pd.to_datetime(df['time'], unit='s')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c02f4804",
      "metadata": {},
      "source": [
        "## 3. Univariate Analysis\n",
        "Let's look at individual distributions for columns like **score** (upvotes), **title length**, etc.\n",
        "\n",
        "### Strategic Questions\n",
        "- **Is the score distribution** highly skewed? Any outliers?\n",
        "- **Do you plan** a log transform for `score`?\n",
        "- **What is** the typical length of a Hacker News title?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "58928077",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score distribution\n",
        "plt.hist(df['score'].dropna(), bins=50)\n",
        "plt.title('Distribution of Hacker News Scores')\n",
        "plt.xlabel('Score')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7c5dd2eb",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Title length distribution\n",
        "df['title_length'] = df['title'].apply(lambda x: len(str(x).split()))\n",
        "\n",
        "plt.hist(df['title_length'], bins=50)\n",
        "plt.title('Distribution of Title Length')\n",
        "plt.xlabel('Number of Words in Title')\n",
        "plt.ylabel('Frequency')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7e10986a",
      "metadata": {},
      "source": [
        "## 4. Author & Domain Exploration\n",
        "We might suspect that certain authors consistently get higher upvotes or that certain domains do better.\n",
        "\n",
        "### Strategic Questions\n",
        "- **Which authors** appear most frequently?\n",
        "- **Do they** also get higher scores on average?\n",
        "- **Any domain** extremely popular or relevant?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bcc9678e",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Top 20 authors by frequency\n",
        "top_authors = df['author'].value_counts().head(20)\n",
        "print(\"Top 20 authors:\\n\", top_authors)\n",
        "\n",
        "# Maybe examine average score for these authors\n",
        "df_top_authors = df[df['author'].isin(top_authors.index)]\n",
        "author_avg_scores = df_top_authors.groupby('author')['score'].mean().sort_values(ascending=False)\n",
        "print(\"\\nAverage scores for top authors:\\n\", author_avg_scores)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "64975616",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Domain frequency (if 'domain' column exists)\n",
        "if 'domain' in df.columns:\n",
        "    top_domains = df['domain'].value_counts().head(20)\n",
        "    print(\"Top 20 domains:\\n\", top_domains)\n",
        "else:\n",
        "    print(\"No 'domain' column found.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7ac7ed0e",
      "metadata": {},
      "source": [
        "## 5. Bivariate Analysis\n",
        "Let's look at relationships between pairs of variables.\n",
        "\n",
        "### Strategic Questions\n",
        "- **Does the length of the title** correlate with the score?\n",
        "- **Is there** any time trend (older posts vs. newer posts)?\n",
        "- **Do high scores** cluster around certain domains or authors?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ceb52fd0",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Score vs. title length scatter\n",
        "plt.scatter(df['title_length'], df['score'], alpha=0.3)\n",
        "plt.title('Score vs. Title Length')\n",
        "plt.xlabel('Title Length (words)')\n",
        "plt.ylabel('Score')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e8fa048",
      "metadata": {},
      "outputs": [],
      "source": [
        "# If there's a time column, see how score changes over time\n",
        "if 'time' in df.columns:\n",
        "    # Convert time to datetime if needed\n",
        "    # df['time'] = pd.to_datetime(df['time'], unit='s')  # uncomment if in UNIX format\n",
        "\n",
        "    df['year_month'] = df['time'].dt.to_period('M')\n",
        "    monthly_scores = df.groupby('year_month')['score'].mean().reset_index()\n",
        "\n",
        "    # Convert year_month to string for plotting\n",
        "    x_vals = monthly_scores['year_month'].astype(str)\n",
        "    y_vals = monthly_scores['score']\n",
        "\n",
        "    plt.plot(x_vals, y_vals)\n",
        "    plt.title('Average Score by Year-Month')\n",
        "    plt.xlabel('Date (Year-Month)')\n",
        "    plt.ylabel('Average Score')\n",
        "    plt.xticks(rotation=45)\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No 'time' column found for time-based analysis.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "83c6a568",
      "metadata": {},
      "source": [
        "## 6. Correlation & Outliers\n",
        "For numeric columns, let's quickly generate a correlation matrix. We'll also look for outliers in `score`.\n",
        "\n",
        "### Strategic Questions\n",
        "- **Which features** have the highest correlation with `score`?\n",
        "- **Do any** columns have surprisingly high or low correlation?\n",
        "- **Should you** remove or transform outliers in `score`?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b619d819",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a subset of numeric columns for correlation\n",
        "numeric_cols = ['score', 'title_length']\n",
        "cols_in_df = [col for col in numeric_cols if col in df.columns]\n",
        "\n",
        "if cols_in_df:\n",
        "    corr_matrix = df[cols_in_df].corr()\n",
        "    print(\"Correlation matrix:\\n\", corr_matrix)\n",
        "\n",
        "    # Plot with matplotlib's imshow\n",
        "    fig, ax = plt.subplots()\n",
        "    cax = ax.imshow(corr_matrix)\n",
        "    ax.set_xticks(range(len(cols_in_df)))\n",
        "    ax.set_yticks(range(len(cols_in_df)))\n",
        "    ax.set_xticklabels(cols_in_df)\n",
        "    ax.set_yticklabels(cols_in_df)\n",
        "    plt.colorbar(cax)\n",
        "    plt.title('Correlation Heatmap')\n",
        "    plt.show()\n",
        "else:\n",
        "    print(\"No numeric columns found for correlation analysis.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "72690646",
      "metadata": {},
      "outputs": [],
      "source": [
        "# Quick look at potential outliers in 'score'\n",
        "score_sorted = df['score'].sort_values(ascending=False)\n",
        "print(\"Top 10 highest scores:\")\n",
        "print(score_sorted.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b0feb20e",
      "metadata": {},
      "source": [
        "## 7. Insights, Questions, and Next Steps\n",
        "### Observations\n",
        "- Are there extremely **high scores** that might skew your model?\n",
        "- Are some authors or domains **dominating** the dataset?\n",
        "- Does the data **span many years** and require a time-based train/test split?\n",
        "\n",
        "### Potential Next Steps\n",
        "1. **Data Cleaning**: Fix missing or null values, unify domain formats (e.g., remove `\"www.\"`).\n",
        "2. **Feature Engineering**: \n",
        "   - Possibly create a `log_score` to reduce the effect of large outliers.\n",
        "   - Encode author/domain for the model (one-hot or embedded).\n",
        "3. **Time-based Split** (if relevant): Train on older data, test on newer.\n",
        "4. **Word2Vec**: Start building a pipeline to embed titles.\n",
        "\n",
        "**Feel free** to expand this notebook with deeper analysis, e.g., comparing top 10 authors over time, or investigating comment counts if available.\n",
        "\n",
        "> **Reminder**: The main goal is to understand the data before jumping into modeling so that you can make informed decisions on feature selection and model architecture."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
